{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1970118-7b46-4dcf-acd2-cd8836d14408",
   "metadata": {
    "name": "md_overview",
    "collapsed": false
   },
   "source": "# 06 Load Excel Files\n\n* Author: Jeremiah Hansen\n* Last Updated: 6/11/2024\n\nThis notebook will load data into the `LOCATION` and `ORDER_DETAIL` tables from Excel files.\n\nThis currently does not use Snowpark File Access as it doesn't yet work in Notebooks. So for now we copy the file locally first."
  },
  {
   "cell_type": "code",
   "id": "8873bc96-287b-4f47-a929-013c1487a088",
   "metadata": {
    "language": "sql",
    "name": "sql_get_context"
   },
   "outputs": [],
   "source": "-- This won't be needed when we can pass variables to Notebooks!\nSELECT current_database() AS DATABASE_NAME, current_schema() AS SCHEMA_NAME",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "py_imports",
    "collapsed": false
   },
   "source": "# Import python packages\nimport logging\nimport pandas as pd\n\nlogger = logging.getLogger(\"demo_logger\")\n\n# Get the target database and schema using the results from the SQL cell above\n# This won't be needed when we can pass variables to Notebooks!\ncurrent_context_df = cells.sql_get_context.to_pandas()\ndatabase_name = current_context_df.iloc[0,0]\nschema_name = current_context_df.iloc[0,1]\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n#session.use_schema(f\"{database_name}.{schema_name}\")\n\nlogger.info(\"06_load_excel_files start\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "413fad43-3fec-4379-b34b-7e1728599a7a",
   "metadata": {
    "language": "sql",
    "name": "sql_get_spreadsheets",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Temporary solution to load in the metadata, this should be replaced with a directy query to a directory table (or a metadata table)\nSELECT '@INTEGRATIONS.FROSTBYTE_RAW_STAGE/intro/order_detail.xlsx' AS STAGE_FILE_PATH, 'order_detail' AS WORKSHEET_NAME, 'ORDER_DETAIL' AS TARGET_TABLE\nUNION\nSELECT '@INTEGRATIONS.FROSTBYTE_RAW_STAGE/intro/location.xlsx', 'location', 'LOCATION';",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "07fd7441-1c12-4195-a7cd-f04fcc3e4242",
   "metadata": {
    "name": "md_function",
    "collapsed": false
   },
   "source": "## Create a function to load Excel worksheet to table\n\nCreate a reusable function to load an Excel worksheet to a table in Snowflake.\n\nNote: Until we can use the `SnowflakeFile` class in Notebooks, we need to temporarily copy the file to a local temp folder and then process from there."
  },
  {
   "cell_type": "code",
   "id": "d92d7957-762a-49ae-95e6-8b407ddba0f6",
   "metadata": {
    "language": "python",
    "name": "py_load_excel_function",
    "collapsed": false
   },
   "outputs": [],
   "source": "import os\nfrom openpyxl import load_workbook\n\ndef load_excel_worksheet_to_table_local(session, stage_file_path, worksheet_name, target_table):\n  local_directory = \"./\"\n  file_name = os.path.basename(stage_file_path)\n\n  # First copy file from stage to local storage\n  get_status = session.file.get(stage_file_path, local_directory)\n\n  with open(f\"{local_directory}{file_name}\", 'rb') as f:\n    workbook = load_workbook(f)\n    sheet = workbook.get_sheet_by_name(worksheet_name)\n    data = sheet.values\n\n    # Get the first line in file as a header line\n    columns = next(data)[0:]\n    # Create a DataFrame based on the second and subsequent lines of data\n    df = pd.DataFrame(data, columns=columns)\n \n    df2 = session.create_dataframe(df)\n    df2.write.mode(\"overwrite\").save_as_table(target_table)\n \n  return True",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "97c2fc79-50d4-4a81-af5d-5c80d37070ec",
   "metadata": {
    "name": "md_process_spreadsheets",
    "collapsed": false
   },
   "source": "## Process all Excel worksheets\n\nLoop through each Excel worksheet to process and call our `load_excel_worksheet_to_table_local()` function."
  },
  {
   "cell_type": "code",
   "id": "4e73f895-6b24-4ce9-b357-7a9a879be1e4",
   "metadata": {
    "language": "python",
    "name": "py_process_spreadsheets"
   },
   "outputs": [],
   "source": "# Process each file from the sql_get_spreadsheets cell above\nfiles_to_load = cells.sql_get_spreadsheets.to_pandas()\nfor index, excel_file in files_to_load.iterrows():\n    logger.info(f\"Processing Excel file {excel_file['STAGE_FILE_PATH']}\")\n    load_excel_worksheet_to_table_local(session, excel_file['STAGE_FILE_PATH'], excel_file['WORKSHEET_NAME'], excel_file['TARGET_TABLE'])\n\nlogger.info(\"06_load_excel_files end\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "16d6be04-3690-4c5d-91ee-5d0d425355b8",
   "metadata": {
    "name": "md_debugging",
    "collapsed": false
   },
   "source": "### Debugging"
  },
  {
   "cell_type": "code",
   "id": "a878dd75-f426-427f-bbef-e5401097d9d6",
   "metadata": {
    "language": "sql",
    "name": "sql_debugging"
   },
   "outputs": [],
   "source": "--DESCRIBE TABLE LOCATION;\n--SELECT * FROM LOCATION;\nSHOW TABLES;",
   "execution_count": null
  }
 ]
}